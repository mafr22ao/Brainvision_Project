{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31c38fb832a78778",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T19:39:14.355310300Z",
     "start_time": "2024-02-22T19:39:14.332993900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_447/4204378327.py:7: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4a30160-4173-4aa8-946a-623088f13953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch torchvision Pillow opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7a6b83c-77af-42b4-bbc9-fef77a80a889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "811abb344e02e927",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T19:41:50.652852700Z",
     "start_time": "2024-02-22T19:41:39.664473400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_image(frame):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return preprocess(frame).unsqueeze(0)\n",
    "\n",
    "def segment_image(img_tensor):\n",
    "    model = models.segmentation.deeplabv3_resnet101(pretrained=True)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)['out'][0]\n",
    "    output_predictions = output.argmax(0)\n",
    "    return output_predictions\n",
    "\n",
    "def calculate_foreground_background(segmented_img):\n",
    "    foreground = (segmented_img != 0).sum()\n",
    "    total_pixels = segmented_img.numel()\n",
    "    background = total_pixels - foreground\n",
    "    foreground_percentage = (foreground.item() / total_pixels) * 100\n",
    "    background_percentage = (background.item() / total_pixels) * 100\n",
    "    return foreground.item(), background_percentage\n",
    "\n",
    "def classify_frames(video_path):\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    if not vidcap.isOpened():\n",
    "        print(f\"Failed to open video file: {video_path}\")\n",
    "        return None\n",
    "\n",
    "    total_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT)) - 1  # Adjusting to avoid reading beyond the last frame\n",
    "\n",
    "    if total_frames == 0:\n",
    "        print(\"The video has no frames.\")\n",
    "        return None\n",
    "\n",
    "    frame_indices = [int(total_frames * i / 4) for i in range(5)]\n",
    "    frame_indices[-1] = min(frame_indices[-1], total_frames - 1)\n",
    "\n",
    "    foreground_pixels_list = []\n",
    "    background_percentage_list = []\n",
    "\n",
    "    for index in frame_indices:\n",
    "        vidcap.set(cv2.CAP_PROP_POS_FRAMES, index)\n",
    "        success, frame = vidcap.read()\n",
    "\n",
    "        if not success:\n",
    "            print(f\"Could not read the frame at index {index}\")\n",
    "            continue\n",
    "\n",
    "        img_tensor = preprocess_image(frame)\n",
    "        segmented_img = segment_image(img_tensor)\n",
    "        foreground_pixels, background_percentage = calculate_foreground_background(segmented_img)\n",
    "\n",
    "        foreground_pixels_list.append(foreground_pixels)\n",
    "        background_percentage_list.append(background_percentage)\n",
    "\n",
    "    vidcap.release()\n",
    "\n",
    "    # Calculate and return the average of foreground pixels and background percentage\n",
    "    avg_foreground_pixels = sum(foreground_pixels_list) / len(foreground_pixels_list)\n",
    "    avg_background_percentage = sum(background_percentage_list) / len(background_percentage_list)\n",
    "\n",
    "    return avg_foreground_pixels, avg_background_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dafecadf4d050619",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T19:41:50.670362500Z",
     "start_time": "2024-02-22T19:41:50.652852700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def classify_folder_scenes(folder_path):\n",
    "    video_files = [f for f in os.listdir(folder_path) \n",
    "                   if os.path.isfile(os.path.join(folder_path, f)) and f.endswith('.mp4')]\n",
    "    data = []\n",
    "\n",
    "    # Wrap video_files with tqdm for progress tracking\n",
    "    for video_file in tqdm(video_files, desc='Classifying videos'):\n",
    "        video_id = video_file[:4]  # Extract video ID from filename\n",
    "        video_path = os.path.join(folder_path, video_file)\n",
    "        avg_foreground_pixels, avg_background_percentage = classify_frames(video_path)\n",
    "        data.append([video_id, avg_foreground_pixels, avg_background_percentage])\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['Video ID', 'Average Foreground Pixels', 'Average Background Percentage'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89e9faf13f5060b3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-22T19:41:50.672308200Z"
    },
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying videos:   0%|          | 0/1102 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet101_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Classifying videos: 100%|██████████| 1102/1102 [1:26:48<00:00,  4.73s/it]\n"
     ]
    }
   ],
   "source": [
    "df_scenes = classify_folder_scenes('AlgonautsVideos268_All_30fpsmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35b71076-42fd-45f8-8198-9ee7f5ac9b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video ID</th>\n",
       "      <th>Average Foreground Pixels</th>\n",
       "      <th>Average Background Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1012</td>\n",
       "      <td>20614.2</td>\n",
       "      <td>58.916215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0039</td>\n",
       "      <td>38298.8</td>\n",
       "      <td>23.671078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0853</td>\n",
       "      <td>4378.8</td>\n",
       "      <td>91.273119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1035</td>\n",
       "      <td>15217.4</td>\n",
       "      <td>69.671955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>0445</td>\n",
       "      <td>1558.2</td>\n",
       "      <td>96.894531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>0542</td>\n",
       "      <td>10990.0</td>\n",
       "      <td>78.097098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>0565</td>\n",
       "      <td>25255.2</td>\n",
       "      <td>49.666773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>1003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>0619</td>\n",
       "      <td>32482.8</td>\n",
       "      <td>35.262277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1102 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Video ID  Average Foreground Pixels  Average Background Percentage\n",
       "0        1012                    20614.2                      58.916215\n",
       "1        0284                        0.0                     100.000000\n",
       "2        0039                    38298.8                      23.671078\n",
       "3        0853                     4378.8                      91.273119\n",
       "4        1035                    15217.4                      69.671955\n",
       "...       ...                        ...                            ...\n",
       "1097     0445                     1558.2                      96.894531\n",
       "1098     0542                    10990.0                      78.097098\n",
       "1099     0565                    25255.2                      49.666773\n",
       "1100     1003                        0.0                     100.000000\n",
       "1101     0619                    32482.8                      35.262277\n",
       "\n",
       "[1102 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e3b8c1b-f906-46b5-9ec2-39e7785c30aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_scenes is your DataFrame variable name\n",
    "df_scenes.to_csv('df_scenes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8a4fbb-a3ee-48d2-bd92-9c5a119c1628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
