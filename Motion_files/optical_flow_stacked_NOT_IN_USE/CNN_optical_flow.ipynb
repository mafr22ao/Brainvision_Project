{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision.models import resnet101, ResNet101_Weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T13:02:36.195580700Z",
     "start_time": "2023-11-27T13:02:36.179565800Z"
    }
   },
   "id": "51d1a92527652a9a"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeysView(NpzFile 'C:/Users/andre/OneDrive/Documents/GitHub/Brainvision_Project/Motion_files/batch_0_Optical_Flow_Stack.npz' with keys: File_ID, Data)\n",
      "Shape of first_video: (1, 16, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "#Load optical flow data from the NPZ file\n",
    "optical_flow_data = np.load(\"C:/Users/andre/OneDrive/Documents/GitHub/Brainvision_Project/Motion_files/batch_0_Optical_Flow_Stack.npz\", allow_pickle=True)\n",
    "\n",
    "print(optical_flow_data.keys())\n",
    "\n",
    "# Assuming the optical flow data is stored in a variable named \"flow_data\"\n",
    "flow_data = optical_flow_data[\"Data\"]\n",
    "\n",
    "# Print the shape of the flow_data array to see its dimensions\n",
    "\n",
    "first_flow_stack = flow_data[0]\n",
    "tensor_input = torch.tensor(first_flow_stack, dtype=torch.float32)\n",
    "print(\"Shape of first_video:\", first_flow_stack.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T13:05:25.794928500Z",
     "start_time": "2023-11-27T13:05:11.793882200Z"
    }
   },
   "id": "a3d4198abc6fd10d"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "class ModifiedResNet101(nn.Module):\n",
    "    def __init__(self, num_classes=101, input_channels=16):\n",
    "        super(ModifiedResNet101, self).__init__()\n",
    "        # Load a pre-trained resnet101 model with the new weights parameter\n",
    "        original_model = resnet101(weights=ResNet101_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        # Modify the first convolutional layer to accept 16-channel input\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            original_model.bn1,\n",
    "            original_model.relu,\n",
    "            original_model.maxpool,\n",
    "        )\n",
    "\n",
    "        # Use the rest of the ResNet101 layers\n",
    "        self.layer1 = original_model.layer1\n",
    "        self.layer2 = original_model.layer2\n",
    "        self.layer3 = original_model.layer3\n",
    "        self.layer4 = original_model.layer4\n",
    "        self.avgpool = original_model.avgpool\n",
    "\n",
    "        # Replace the final fully connected layer\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "model = ModifiedResNet101(num_classes=101, input_channels=16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T12:50:03.051949900Z",
     "start_time": "2023-11-27T12:50:02.002036700Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: False\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA Available:\", cuda_available)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T12:48:32.968443Z",
     "start_time": "2023-11-27T12:48:32.952819600Z"
    }
   },
   "id": "348faef7b57ff385"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# Move the model to GPU if CUDA is available\n",
    "if cuda_available:\n",
    "    model = model.to('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T12:48:58.721684700Z",
     "start_time": "2023-11-27T12:48:58.705874700Z"
    }
   },
   "id": "abb6d417da061a1c"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2603, -0.3102, -0.0202, -0.7101, -0.1261, -0.0641,  0.3179, -0.2516,\n",
      "         -0.4431, -0.1020,  0.0798,  0.0928, -0.0255, -0.0878,  0.4197,  0.2188,\n",
      "          0.3150, -0.1335,  0.3236, -0.1151,  0.1148,  0.2013,  0.2850,  0.4231,\n",
      "          0.2522, -0.2313, -0.1374,  0.2470, -0.2998,  0.3614, -0.1070, -0.4153,\n",
      "          0.4068,  0.4375, -0.0156,  0.1833, -1.0190, -0.1713, -0.0254, -0.0605,\n",
      "         -0.0642, -0.2885,  0.0724,  0.0874, -0.2186, -0.1717, -0.2342, -0.1904,\n",
      "         -0.2229, -0.1224, -0.6913, -0.5461, -0.5211,  0.3701, -0.2457,  0.0075,\n",
      "         -0.0931, -0.2141,  0.2392,  0.2626, -0.5643, -0.0110,  0.0423,  0.2375,\n",
      "         -0.4816,  0.1227, -0.2379,  0.1232,  0.5849,  0.0737, -0.0916, -0.1800,\n",
      "         -0.2122,  0.2754,  0.4036,  0.2834,  0.0301, -0.0661,  0.0038,  0.1998,\n",
      "         -0.0376, -0.2857, -0.2048,  0.0101, -0.2800, -0.1542, -0.1200,  0.4165,\n",
      "         -0.0175, -0.3150, -0.0468, -0.1390, -0.6246,  0.0685,  0.2680,  0.4889,\n",
      "          0.2042, -0.1394, -0.1449, -0.0496, -0.0999]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example of using the model with a dummy input\n",
    "dummy_input = tensor_input  \n",
    "# Move the data to GPU if CUDA is available\n",
    "if cuda_available:\n",
    "    dummy_input = dummy_input.to('cuda')\n",
    "\n",
    "# Forward pass\n",
    "output = model(dummy_input)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T13:05:37.133253400Z",
     "start_time": "2023-11-27T13:05:36.536660500Z"
    }
   },
   "id": "6278e88264c4931f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d0ed5105f2f9f14d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
