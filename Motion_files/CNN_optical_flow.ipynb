{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:22:39.287968Z",
     "start_time": "2023-11-26T20:22:39.275889900Z"
    }
   },
   "id": "51d1a92527652a9a"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class TemporalStreamConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TemporalStreamConvNet, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=2, out_channels=96, kernel_size=7, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1)\n",
    "\n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc6 = nn.Linear(in_features=4608, out_features=4096) # Adjust in_features based on the output of conv5\n",
    "        self.fc7 = nn.Linear(in_features=4096, out_features=2048)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutions, batch normalization, ReLU activations, and pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(F.relu(self.conv5(x)))\n",
    "\n",
    "        # Flatten the output for the fully connected layer\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # Apply fully connected layers with dropout\n",
    "        x = self.dropout(F.relu(self.fc6(x)))\n",
    "        x = self.dropout(F.relu(self.fc7(x)))\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:27:33.111941800Z",
     "start_time": "2023-11-26T20:27:33.090929500Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: False\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA Available:\", cuda_available)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:27:35.653690400Z",
     "start_time": "2023-11-26T20:27:35.478326Z"
    }
   },
   "id": "348faef7b57ff385"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = TemporalStreamConvNet()\n",
    "# Move the model to GPU if CUDA is available\n",
    "if cuda_available:\n",
    "    model = model.to('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:27:40.816098800Z",
     "start_time": "2023-11-26T20:27:40.703187300Z"
    }
   },
   "id": "abb6d417da061a1c"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0104, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example of using the model with a dummy input\n",
    "dummy_input = torch.randn(1, 2, 224, 224)  # Example input tensor; adjust the size as needed\n",
    "\n",
    "# Move the data to GPU if CUDA is available\n",
    "if cuda_available:\n",
    "    dummy_input = dummy_input.to('cuda')\n",
    "\n",
    "# Forward pass\n",
    "output = model(dummy_input)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T20:27:41.491376400Z",
     "start_time": "2023-11-26T20:27:41.442770100Z"
    }
   },
   "id": "6278e88264c4931f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "67e97065a9373636"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
