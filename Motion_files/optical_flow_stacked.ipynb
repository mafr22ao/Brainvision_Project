{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Optical flow calculation per video"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6d63256e28adfdf"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from cv2 import VideoCapture, cvtColor, COLOR_BGR2GRAY, calcOpticalFlowFarneback\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T21:02:38.432613400Z",
     "start_time": "2023-11-25T21:02:38.419110200Z"
    }
   },
   "id": "ed38d43c81e037de"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def calculate_optical_flow(video_path, L=5):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Failed to open video: {video_path}\")\n",
    "        return []\n",
    "\n",
    "    ret, frame1 = cap.read()\n",
    "    prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Initialize lists to store optical flow components and angles for L frames\n",
    "    flow_stack = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame2 = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate optical flow\n",
    "        flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        \n",
    "        # Split the flow into horizontal and vertical components\n",
    "        flow_horizontal, flow_vertical = flow[..., 0], flow[..., 1]\n",
    "\n",
    "        # Calculate the angle of the flow\n",
    "        angle = np.arctan2(flow_vertical, flow_horizontal)\n",
    "\n",
    "        # Add to flow stack\n",
    "        flow_stack.extend([flow_horizontal, flow_vertical, angle])\n",
    "\n",
    "        # If the flow_stack has 3L channels (horizontal, vertical, angle), stop adding more\n",
    "        if len(flow_stack) == 3 * L:\n",
    "            break\n",
    "\n",
    "        prvs = next\n",
    "\n",
    "    cap.release()\n",
    "    return np.stack(flow_stack, axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T21:02:38.982309900Z",
     "start_time": "2023-11-25T21:02:38.968788700Z"
    }
   },
   "id": "55eddffd4346e29d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def process_batch(video_paths, L=5):\n",
    "    file_identifiers = []\n",
    "    all_flow_stacks = []\n",
    "    flow_averages = []\n",
    "    flow_maximums = []\n",
    "    angle_averages = []\n",
    "    angle_maximums = []\n",
    "\n",
    "    for path in tqdm(video_paths, desc=\"Processing Videos\"):\n",
    "        # Extract file identifier\n",
    "        file_name = os.path.basename(path)\n",
    "        identifier = re.match(r'(\\d{4})_', file_name)\n",
    "        file_id = identifier.group(1) if identifier else \"Unknown\"\n",
    "    \n",
    "        # Calculate optical flow stack\n",
    "        flow_stack = calculate_optical_flow(path, L)\n",
    "\n",
    "        # Calculate average and maximum flow (horizontal and vertical components)\n",
    "        avg_flow = np.mean(flow_stack[..., :2 * L])  # Exclude angles for average flow calculation\n",
    "        max_flow = np.max(flow_stack[..., :2 * L])  # Exclude angles for maximum flow calculation\n",
    "\n",
    "        # Calculate average and maximum angle\n",
    "        avg_angle = np.mean(flow_stack[..., 2 * L:])  # Consider only angles\n",
    "        max_angle = np.max(flow_stack[..., 2 * L:])  # Consider only angles\n",
    "    \n",
    "        # Append to lists\n",
    "        file_identifiers.append(file_id)\n",
    "        all_flow_stacks.append(flow_stack)\n",
    "        flow_averages.append(avg_flow)\n",
    "        flow_maximums.append(max_flow)\n",
    "        angle_averages.append(avg_angle)\n",
    "        angle_maximums.append(max_angle)\n",
    "\n",
    "    # Create DataFrame for the batch\n",
    "    batch_df = pd.DataFrame({\n",
    "        'File_ID': file_identifiers,\n",
    "        'Optical_Flow_Stack': all_flow_stacks,\n",
    "        'Average_Flow': flow_averages,\n",
    "        'Maximum_Flow': flow_maximums,\n",
    "        'Average_Angle': angle_averages,\n",
    "        'Maximum_Angle': angle_maximums\n",
    "    })\n",
    "\n",
    "    return batch_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T19:42:55.701724900Z",
     "start_time": "2023-11-25T19:42:55.692516Z"
    }
   },
   "id": "2407d1ec3552e7a1"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#Directory containing the videos\n",
    "video_directory = \"./AlgonautsVideos268_All_30fpsmax\"\n",
    "video_paths = glob.glob(os.path.join(video_directory, \"*.mp4\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T18:55:36.752437700Z",
     "start_time": "2023-11-25T18:55:36.730647400Z"
    }
   },
   "id": "d357357a4faf0b1e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Parameters\n",
    "batch_size = 100\n",
    "total_videos = len(video_paths)\n",
    "num_batches = total_videos // batch_size + (1 if total_videos % batch_size != 0 else 0)\n",
    "\n",
    "\n",
    "# Function to get the last processed batch number\n",
    "def get_last_processed_batch():\n",
    "    try:\n",
    "        with open('last_processed_batch.txt', 'r') as file:\n",
    "            return int(file.read().strip())\n",
    "    except FileNotFoundError:\n",
    "        return 0\n",
    "\n",
    "# Function to save the last processed batch number\n",
    "def save_last_processed_batch(batch_number):\n",
    "    with open('last_processed_batch.txt', 'w') as file:\n",
    "        file.write(str(batch_number))\n",
    "\n",
    "\n",
    "# Start processing from the last processed batch\n",
    "start_batch = get_last_processed_batch()\n",
    "\n",
    "for batch_number in tqdm(range(start_batch, num_batches), desc=\"Processing Batches\"):\n",
    "    try:\n",
    "        start_index = batch_number * batch_size\n",
    "        end_index = min(start_index + batch_size, total_videos)\n",
    "        current_batch_paths = video_paths[start_index:end_index]\n",
    "\n",
    "        # Process the batch and create a dataframe\n",
    "        batch_df = process_batch(current_batch_paths)\n",
    "\n",
    "        # Save each column with File_IDs in separate NPZ files\n",
    "        for column in ['Optical_Flow_Stack', 'Average_Flow', 'Maximum_Flow', 'Average_Angle', 'Maximum_Angle']:\n",
    "            np.savez_compressed(f'batch_{batch_number}_{column}.npz', File_ID=batch_df['File_ID'].to_numpy(), Data=batch_df[column].to_numpy())\n",
    "\n",
    "        # Clear memory\n",
    "        del batch_df\n",
    "        gc.collect()\n",
    "\n",
    "        # Save the last processed batch number\n",
    "        save_last_processed_batch(batch_number)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred in batch {batch_number}: {e}\")\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0c8773784606b1a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
