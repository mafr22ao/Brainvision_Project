{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def fmri_preprocessing():\n",
    "#     \"\"\"\n",
    "#     conducts remaining preprocessing steps on the fmris\n",
    "#     :return: saves the preprocessed files for later use\n",
    "#     \"\"\"\n",
    "#     import pickle\n",
    "#     def load_dict(filename_):\n",
    "#         with open(filename_, 'rb') as f:\n",
    "#             u = pickle._Unpickler(f)\n",
    "#             u.encoding = 'latin1'\n",
    "#             ret_di = u.load()\n",
    "#         return ret_di\n",
    "# \n",
    "#     # path to ROI file\n",
    "#     ROI_file = \"participants_data_v2021/full_track/sub04/WB.pkl\"\n",
    "# \n",
    "#     # loading .pkl file\n",
    "#     ROI_data = load_dict(ROI_file)\n",
    "#     print(ROI_data.keys())\n",
    "# \n",
    "#     # print the data dimensions:\n",
    "#     print(ROI_data['train'].shape)\n",
    "#     print(ROI_data['voxel_mask'].shape)\n",
    "# \n",
    "#     # data shape: (1000, 3, 19445) - three measurements for 1000 videos of subject4, who has 19445 voxels\n",
    "#     # mask shape: voxels are organized in a space of (78x93x71) voxels\n",
    "# \n",
    "#     print(\"This has not be implemented yet.\")\n",
    "# \n",
    "# # voxel correlations (taken from CCN2021_Algonauts)\n",
    "# def vectorized_correlation(x,y):\n",
    "#     dim = 0\n",
    "# \n",
    "#     centered_x = x - x.mean(axis=dim, keepdims=True)\n",
    "#     centered_y = y - y.mean(axis=dim, keepdims=True)\n",
    "# \n",
    "#     covariance = (centered_x * centered_y).sum(axis=dim, keepdims=True)\n",
    "# \n",
    "#     covariance = covariance / (x.shape[dim])\n",
    "# \n",
    "#     x_std = x.std(axis=dim, keepdims=True)+1e-8\n",
    "#     y_std = y.std(axis=dim, keepdims=True)+1e-8\n",
    "# \n",
    "#     corr = covariance / (x_std * y_std)\n",
    "# \n",
    "#     return corr.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of fmri data for sub01: (1000, 3, 18222)\n",
      "Shape of fmri data for sub02: (1000, 3, 21573)\n",
      "Shape of fmri data for sub03: (1000, 3, 15225)\n",
      "Shape of fmri data for sub04: (1000, 3, 19445)\n",
      "Shape of fmri data for sub05: (1000, 3, 13340)\n",
      "Shape of fmri data for sub06: (1000, 3, 19818)\n",
      "Shape of fmri data for sub07: (1000, 3, 10836)\n",
      "Shape of fmri data for sub08: (1000, 3, 12347)\n",
      "Shape of fmri data for sub09: (1000, 3, 17570)\n",
      "Shape of fmri data for sub10: (1000, 3, 12950)\n"
     ]
    }
   ],
   "source": [
    "# shapes of fmri scans: differ a lot, i.e. sub2 has double the size of sub7. Because of that, combining the scans to a common label does not seem feasible\n",
    "import pickle\n",
    "\n",
    "# Load the object from the PKL file\n",
    "for sub in [\"sub01\",\"sub02\",\"sub03\",\"sub04\",\"sub05\",\"sub06\",\"sub07\",\"sub08\",\"sub09\",\"sub10\"]:\n",
    "    with open(f'./participants_data_v2021/full_track/{sub}/WB.pkl', 'rb') as file:\n",
    "        loaded_object = pickle.load(file)\n",
    "    \n",
    "    voxel_data = loaded_object.get(\"train\")\n",
    "    print(f\"Shape of fmri data for {sub}:\", voxel_data.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:53:48.379256500Z",
     "start_time": "2023-11-28T17:53:43.852207200Z"
    }
   },
   "id": "4424b08d44f1c0bd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
