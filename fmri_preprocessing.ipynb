{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def fmri_preprocessing():\n",
    "#     \"\"\"\n",
    "#     conducts remaining preprocessing steps on the fmris\n",
    "#     :return: saves the preprocessed files for later use\n",
    "#     \"\"\"\n",
    "#     import pickle\n",
    "#     def load_dict(filename_):\n",
    "#         with open(filename_, 'rb') as f:\n",
    "#             u = pickle._Unpickler(f)\n",
    "#             u.encoding = 'latin1'\n",
    "#             ret_di = u.load()\n",
    "#         return ret_di\n",
    "# \n",
    "#     # path to ROI file\n",
    "#     ROI_file = \"participants_data_v2021/full_track/sub04/WB.pkl\"\n",
    "# \n",
    "#     # loading .pkl file\n",
    "#     ROI_data = load_dict(ROI_file)\n",
    "#     print(ROI_data.keys())\n",
    "# \n",
    "#     # print the data dimensions:\n",
    "#     print(ROI_data['train'].shape)\n",
    "#     print(ROI_data['voxel_mask'].shape)\n",
    "# \n",
    "#     # data shape: (1000, 3, 19445) - three measurements for 1000 videos of subject4, who has 19445 voxels\n",
    "#     # mask shape: voxels are organized in a space of (78x93x71) voxels\n",
    "# \n",
    "#     print(\"This has not be implemented yet.\")\n",
    "# \n",
    "# # voxel correlations (taken from CCN2021_Algonauts)\n",
    "# def vectorized_correlation(x,y):\n",
    "#     dim = 0\n",
    "# \n",
    "#     centered_x = x - x.mean(axis=dim, keepdims=True)\n",
    "#     centered_y = y - y.mean(axis=dim, keepdims=True)\n",
    "# \n",
    "#     covariance = (centered_x * centered_y).sum(axis=dim, keepdims=True)\n",
    "# \n",
    "#     covariance = covariance / (x.shape[dim])\n",
    "# \n",
    "#     x_std = x.std(axis=dim, keepdims=True)+1e-8\n",
    "#     y_std = y.std(axis=dim, keepdims=True)+1e-8\n",
    "# \n",
    "#     corr = covariance / (x_std * y_std)\n",
    "# \n",
    "#     return corr.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of fmri data for sub01: (1000, 3, 18222)\n",
      "Shape of fmri data for sub02: (1000, 3, 21573)\n",
      "Shape of fmri data for sub03: (1000, 3, 15225)\n",
      "Shape of fmri data for sub04: (1000, 3, 19445)\n",
      "Shape of fmri data for sub05: (1000, 3, 13340)\n",
      "Shape of fmri data for sub06: (1000, 3, 19818)\n",
      "Shape of fmri data for sub07: (1000, 3, 10836)\n",
      "Shape of fmri data for sub08: (1000, 3, 12347)\n",
      "Shape of fmri data for sub09: (1000, 3, 17570)\n",
      "Shape of fmri data for sub10: (1000, 3, 12950)\n"
     ]
    }
   ],
   "source": [
    "# shapes of fmri scans: differ a lot, i.e. sub2 has double the size of sub7. Because of that, combining the scans to a common label does not seem feasible\n",
    "import pickle\n",
    "\n",
    "# Load the object from the PKL file\n",
    "for sub in [\"sub01\",\"sub02\",\"sub03\",\"sub04\",\"sub05\",\"sub06\",\"sub07\",\"sub08\",\"sub09\",\"sub10\"]:\n",
    "    with open(f'./participants_data_v2021/full_track/{sub}/WB.pkl', 'rb') as file:\n",
    "        loaded_object = pickle.load(file)\n",
    "    \n",
    "    voxel_data = loaded_object.get(\"train\")\n",
    "    print(f\"Shape of fmri data for {sub}:\", voxel_data.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:53:48.379256500Z",
     "start_time": "2023-11-28T17:53:43.852207200Z"
    }
   },
   "id": "4424b08d44f1c0bd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cf9da5a66682c412"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T21:00:44.393381300Z",
     "start_time": "2023-11-30T21:00:44.382285500Z"
    }
   },
   "id": "74097d391308eb11"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# get shapes of ROI data per subject\n",
    "\n",
    "def load_dict(filename_):\n",
    "    with open(filename_, 'rb') as f:\n",
    "        u = pickle._Unpickler(f)\n",
    "        u.encoding = 'latin1'\n",
    "        ret_di = u.load()\n",
    "    return ret_di\n",
    "\n",
    "def get_fmri(sub, ROI, avg=True):\n",
    "    \"\"\"\n",
    "    Loads fMRI data for a specified ROI into a numpy array.\n",
    "\n",
    "    Parameters:\n",
    "    fmri_dir (str): Path to fMRI data.\n",
    "    ROI (str): Name of the ROI.\n",
    "    avg (bool, optional): If True, average data across repetitions. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "    np.array: fMRI response matrix (dimensions: #train_vids x #repetitions x #voxels).\n",
    "    (Optional) np.array: Voxel mask for the 'WB' ROI.\n",
    "    \"\"\"\n",
    "    fmri_dir = './participants_data_v2021'\n",
    "    if ROI == \"WB\":\n",
    "        track = \"full_track\"\n",
    "    else:\n",
    "        track = \"mini_track\"\n",
    "    track_dir = os.path.join(fmri_dir, track)\n",
    "    sub_fmri_dir = os.path.join(track_dir, sub)\n",
    "    \n",
    "    ROI_data = load_dict(os.path.join(sub_fmri_dir, f\"{ROI}.pkl\"))\n",
    "    data = np.mean(ROI_data[\"train\"], axis=1) if avg else ROI_data[\"train\"]\n",
    "    return (data, ROI_data['voxel_mask']) if ROI == \"WB\" else data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T21:55:57.414921200Z",
     "start_time": "2023-11-30T21:55:57.389085600Z"
    }
   },
   "id": "1feb9b6cb99a026b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\marce\\\\PycharmProjects\\\\Brainvision_Project'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T20:50:19.759076800Z",
     "start_time": "2023-11-30T20:50:19.743267400Z"
    }
   },
   "id": "6b34a8891cfbbb65"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                V1           V2           V3           V4           LOC  \\\n",
      "sub01  (1000, 232)  (1000, 231)  (1000, 261)  (1000, 107)  (1000, 1843)   \n",
      "sub02  (1000, 285)  (1000, 231)  (1000, 270)   (1000, 95)  (1000, 1348)   \n",
      "sub03  (1000, 164)  (1000, 271)  (1000, 270)  (1000, 111)  (1000, 1237)   \n",
      "sub04  (1000, 176)  (1000, 209)  (1000, 212)  (1000, 117)  (1000, 1153)   \n",
      "sub05  (1000, 326)  (1000, 196)  (1000, 176)   (1000, 73)  (1000, 1397)   \n",
      "sub06  (1000, 286)  (1000, 281)  (1000, 229)  (1000, 108)  (1000, 1356)   \n",
      "sub07  (1000, 195)  (1000, 189)  (1000, 174)   (1000, 55)  (1000, 1117)   \n",
      "sub08  (1000, 300)  (1000, 238)  (1000, 223)   (1000, 85)  (1000, 1244)   \n",
      "sub09  (1000, 271)  (1000, 265)  (1000, 245)   (1000, 94)  (1000, 1515)   \n",
      "sub10  (1000, 238)  (1000, 249)  (1000, 188)   (1000, 60)  (1000, 1034)   \n",
      "\n",
      "               EBA          FFA          STS          PPA             WB  \n",
      "sub01  (1000, 351)   (1000, 68)  (1000, 341)  (1000, 425)  (1000, 18222)  \n",
      "sub02  (1000, 183)  (1000, 157)  (1000, 421)  (1000, 153)  (1000, 21573)  \n",
      "sub03  (1000, 376)   (1000, 80)  (1000, 278)  (1000, 368)  (1000, 15225)  \n",
      "sub04  (1000, 368)  (1000, 210)  (1000, 398)  (1000, 225)  (1000, 19445)  \n",
      "sub05  (1000, 309)   (1000, 69)  (1000, 219)  (1000, 210)  (1000, 13340)  \n",
      "sub06  (1000, 308)  (1000, 119)  (1000, 173)  (1000, 216)  (1000, 19818)  \n",
      "sub07  (1000, 101)   (1000, 89)   (1000, 80)   (1000, 33)  (1000, 10836)  \n",
      "sub08   (1000, 55)  (1000, 163)  (1000, 306)  (1000, 150)  (1000, 12347)  \n",
      "sub09  (1000, 191)   (1000, 76)  (1000, 346)  (1000, 262)  (1000, 17570)  \n",
      "sub10  (1000, 162)   (1000, 69)  (1000, 120)  (1000, 165)  (1000, 12950)  \n"
     ]
    }
   ],
   "source": [
    "# Subjects and ROIs\n",
    "subs = [\"sub01\", \"sub02\", \"sub03\", \"sub04\", \"sub05\", \"sub06\", \"sub07\", \"sub08\", \"sub09\", \"sub10\"]\n",
    "ROIs = [\"V1\", \"V2\", \"V3\", \"V4\", \"LOC\", \"EBA\", \"FFA\", \"STS\", \"PPA\", \"WB\"]\n",
    "\n",
    "# Initialize a DataFrame to store shapes\n",
    "shape_table = pd.DataFrame(index=subs, columns=ROIs)\n",
    "\n",
    "# Loop through subjects and ROIs\n",
    "for sub in subs:\n",
    "    for ROI in ROIs:\n",
    "        fmri_data = get_fmri(sub, ROI)\n",
    "        # Store the shape (excluding voxel_mask if present)\n",
    "        shape_table.at[sub, ROI] = fmri_data[0].shape if isinstance(fmri_data, tuple) else fmri_data.shape\n",
    "\n",
    "# Display the table\n",
    "print(shape_table)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T21:56:05.365506Z",
     "start_time": "2023-11-30T21:56:00.370967Z"
    }
   },
   "id": "5a559693ccc21f05"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Number of voxels in ROIs differ a lot across subjects."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee24e75f072d1153"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train'])\n"
     ]
    }
   ],
   "source": [
    "# Checking for voxel mask in ROI data\n",
    "ROI_file = os.path.join('participants_data_v2021/mini_track', \"sub01/EBA.pkl\")\n",
    "ROI_data = load_dict(ROI_file)\n",
    "print(ROI_data.keys())\n",
    "# no voxel mask for ROIs, only for \"WB\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T21:41:34.042443400Z",
     "start_time": "2023-11-30T21:41:34.032360600Z"
    }
   },
   "id": "67d6ed9dd680405b"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ROIs_sum     WB\n",
      "sub01     3859  18222\n",
      "sub02     3143  21573\n",
      "sub03     3155  15225\n",
      "sub04     3068  19445\n",
      "sub05     2975  13340\n",
      "sub06     3076  19818\n",
      "sub07     2033  10836\n",
      "sub08     2764  12347\n",
      "sub09     3265  17570\n",
      "sub10     2285  12950\n"
     ]
    }
   ],
   "source": [
    "# do sum of number of voxels of ROI arrays correspond to \"WB\" array number of voxels?\n",
    "\n",
    "dimension_table = pd.DataFrame(index=subs, columns=[\"ROIs_sum\", \"WB\"])\n",
    "\n",
    "# Loop to compute the dimensions for each subject\n",
    "for sub in subs:\n",
    "    sum_second_dim = 0\n",
    "    wb_second_dim = None\n",
    "\n",
    "    for ROI in ROIs:\n",
    "        fmri_data = get_fmri(sub, ROI)\n",
    "        data = fmri_data[0] if isinstance(fmri_data, tuple) else fmri_data\n",
    "        if ROI == \"WB\":\n",
    "            wb_second_dim = data.shape[1]\n",
    "        else:\n",
    "            sum_second_dim += data.shape[1]\n",
    "\n",
    "    # Store the computed dimensions in the DataFrame\n",
    "    dimension_table.at[sub, \"ROIs_sum\"] = sum_second_dim\n",
    "    dimension_table.at[sub, \"WB\"] = wb_second_dim\n",
    "\n",
    "# Display the table\n",
    "print(dimension_table)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T22:24:44.888900400Z",
     "start_time": "2023-11-30T22:24:42.183465Z"
    }
   },
   "id": "2e4e54fea5514814"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check if after applying voxel mask on WB the number of voxels corresponds to ROIs sum\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cb1506d2defbfc5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# to visualize activity, a voxel mask is needed that maps the 1d ROI arrays into 3d space\n",
    "\n",
    "from nilearn import plotting\n",
    "from utils import find_repo_root\n",
    "\n",
    "def visualize_activity(vid_id, sub, ROI):\n",
    "    # Setting up the paths for ROI data\n",
    "    fmri_dir = './participants_data_v2021'\n",
    "    track = \"mini_track\" \n",
    "    # Get the right track directory\n",
    "    track_dir = os.path.join(fmri_dir, track)\n",
    "    sub_fmri_dir = os.path.join(track_dir, sub)\n",
    "\n",
    "    # Result directory to store NIfTI file\n",
    "    results_dir = find_repo_root()\n",
    "\n",
    "    # Mapping the data to voxels and storing in a NIfTI file\n",
    "    fmri_train = get_fmri(sub_fmri_dir, ROI)\n",
    "\n",
    "    # Adjusting this part for ROI\n",
    "    # Assuming fmri_train is now a 2D array of shape (#vids, #voxels)\n",
    "    fmri_response = fmri_train[vid_id, :]\n",
    "\n",
    "    # You need a mask or a method to map these voxels back to 3D space\n",
    "    # Let's assume you have a function to do this mapping\n",
    "    visual_mask_3D = map_to_3D(fmri_response, ROI)  # This is a hypothetical function\n",
    "\n",
    "    # Save path for the NIfTI file\n",
    "    nii_save_path = os.path.join(results_dir, f'{ROI}_activity.nii')\n",
    "\n",
    "    # Use a brain mask specific to your ROI or a generic brain mask\n",
    "    brain_mask = './example.nii'  # Update this path to your brain mask\n",
    "    saveasnii(brain_mask, nii_save_path, visual_mask_3D)\n",
    "\n",
    "    # Visualizing saved NIfTI file\n",
    "    plotting.plot_glass_brain(nii_save_path,\n",
    "                              title=f'fMRI response in {ROI}', plot_abs=False,\n",
    "                              display_mode='lyr', colorbar=True)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ada71453bbf6899f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "99b3caf04386015"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
