{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-01T15:04:58.095363500Z",
     "start_time": "2023-12-01T15:04:58.089222300Z"
    }
   },
   "outputs": [],
   "source": [
    "from fmri_preprocessing import vectorized_correlation\n",
    "from utils import find_repo_root\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Function Definitions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cef70d0abaf40bf4"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def load_dict(filename_):\n",
    "    with open(filename_, 'rb') as f:\n",
    "        u = pickle._Unpickler(f)\n",
    "        u.encoding = 'latin1'\n",
    "        ret_di = u.load()\n",
    "    return ret_di"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T15:04:58.979137300Z",
     "start_time": "2023-12-01T15:04:58.969388800Z"
    }
   },
   "id": "5f6f2b3be460cbb0"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# fast linear regression function with Pytorch (taken from CCN2021_Algonauts.ipynb)\n",
    "# class OLS_pytorch(object):\n",
    "#     def __init__(self,use_gpu=False):\n",
    "#         self.coefficients = []\n",
    "#         self.use_gpu = use_gpu\n",
    "#         self.X = None\n",
    "#         self.y = None\n",
    "# \n",
    "#     def fit(self,X,y):\n",
    "#         if len(X.shape) == 1:\n",
    "#             X = self._reshape_x(X)\n",
    "#         if len(y.shape) == 1:\n",
    "#             y = self._reshape_x(y)\n",
    "# \n",
    "#         X =  self._concatenate_ones(X)\n",
    "# \n",
    "#         X = torch.from_numpy(X).float()\n",
    "#         y = torch.from_numpy(y).float()\n",
    "#         if self.use_gpu:\n",
    "#             X = X.cuda()\n",
    "#             y = y.cuda()\n",
    "#         XtX = torch.matmul(X.t(),X)\n",
    "#         Xty = torch.matmul(X.t(),y.unsqueeze(2))\n",
    "#         XtX = XtX.unsqueeze(0)\n",
    "#         XtX = torch.repeat_interleave(XtX, y.shape[0], dim=0)\n",
    "#         betas_cholesky, _ = torch.solve(Xty, XtX)\n",
    "# \n",
    "#         self.coefficients = betas_cholesky\n",
    "# \n",
    "#     def predict(self, entry):\n",
    "#         if len(entry.shape) == 1:\n",
    "#             entry = self._reshape_x(entry)\n",
    "#         entry =  self._concatenate_ones(entry)\n",
    "#         entry = torch.from_numpy(entry).float()\n",
    "#         if self.use_gpu:\n",
    "#             entry = entry.cuda()\n",
    "#         prediction = torch.matmul(entry,self.coefficients)\n",
    "#         prediction = prediction.cpu().numpy()\n",
    "#         prediction = np.squeeze(prediction).T\n",
    "#         return prediction\n",
    "# \n",
    "#     def _reshape_x(self,X):\n",
    "#         return X.reshape(-1,1)\n",
    "# \n",
    "#     def _concatenate_ones(self,X):\n",
    "#         ones = np.ones(shape=X.shape[0]).reshape(-1,1)\n",
    "#         return np.concatenate((ones,X),1)\n",
    "\n",
    "# def predict_fmri_fast(train_activations, test_activations, train_fmri,use_gpu=False):\n",
    "#     \"\"\"This function fits a linear regressor using train_activations and train_fmri,\n",
    "#     then returns the predicted fmri_pred_test using the fitted weights and\n",
    "#     test_activations.\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     train_activations : np.array\n",
    "#         matrix of dimensions #train_vids x #pca_components\n",
    "#         containing activations of train videos.\n",
    "#     test_activations : np.array\n",
    "#         matrix of dimensions #test_vids x #pca_components\n",
    "#         containing activations of test videos\n",
    "#     train_fmri : np.array\n",
    "#         matrix of dimensions #train_vids x  #voxels\n",
    "#         containing fMRI responses to train videos\n",
    "#     use_gpu : bool\n",
    "#         whether to use gpu or not.\n",
    "#     Returns\n",
    "#     -------\n",
    "#     fmri_pred_test: np.array\n",
    "#         matrix of dimensions #test_vids x  #voxels\n",
    "#         containing predicted fMRI responses to test videos .\n",
    "#     \"\"\"\n",
    "# \n",
    "#     reg = OLS_pytorch(use_gpu)\n",
    "#     reg.fit(train_activations,train_fmri.T)\n",
    "#     fmri_pred_test = reg.predict(test_activations)\n",
    "#     return fmri_pred_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T15:04:59.373172700Z",
     "start_time": "2023-12-01T15:04:59.373172700Z"
    }
   },
   "id": "491bdd0a0cbb2ade"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def get_fmri(fmri_dir, ROI):\n",
    "    \"\"\"This function loads fMRI data into a numpy array for to a given ROI.\n",
    "    Parameters\n",
    "    ----------\n",
    "    fmri_dir : str\n",
    "        path to fMRI data. Relates to a specific subject.\n",
    "    ROI : str\n",
    "        name of ROI.\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        matrix of dimensions #train_vids x #repetitions x #voxels\n",
    "        containing fMRI responses to train videos of a given ROI\n",
    "    \"\"\"\n",
    "\n",
    "    # Loading ROI data\n",
    "    # ToDo: if necessary, adjust path as soon as preprocessing is done\n",
    "    ROI_file = os.path.join(fmri_dir, ROI + \".pkl\")\n",
    "    ROI_data = load_dict(ROI_file)\n",
    "\n",
    "    # averaging ROI data across repetitions\n",
    "    ROI_data_train = np.mean(ROI_data[\"train\"], axis = 1)\n",
    "    if ROI == \"WB\":\n",
    "        voxel_mask = ROI_data['voxel_mask']\n",
    "        return ROI_data_train, voxel_mask\n",
    "\n",
    "    return ROI_data_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T15:04:59.912419300Z",
     "start_time": "2023-12-01T15:04:59.908942100Z"
    }
   },
   "id": "5dd959a6472e9324"
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "# Dense Layer\n",
    "def train_model(X_train, X_val, y_train, y_val, num_epochs = 10):\n",
    "    \"\"\"\n",
    "    conducts the training for a particular layer, subject & ROI\n",
    "    :param X_train: training data (feature map PCs from first 800 videos from a particular layer)\n",
    "    :param X_val: validation data (feature map PCs from videos 801-900 from a particular layer)\n",
    "    :param y_train: training labels (scans for first 800 videos for the particular subject & ROI)\n",
    "    :param y_val: training labels (scans for videos 801-900 for the particular subject & ROI)\n",
    "    :param num_epochs: number of epochs for training\n",
    "    :return: model parameters & validation accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    # flatten X data over 2nd and 3rd dimension\n",
    "    X_train = X_train.reshape(800, -1)\n",
    "    X_val =  X_val.reshape(100, -1)\n",
    "\n",
    "    print(\"X_train shape: \", X_train.shape)\n",
    "    print(\"y_train shape: \", y_train.shape)\n",
    "    print(\"X_val shape: \", X_val.shape)\n",
    "    print(\"y_val shape: \", y_val.shape)\n",
    "    # specify number of neurons per layer, depending on the number of inputs from a particular layer and number of output voxels\n",
    "    input_neurons = X_train.shape[1]\n",
    "    hidden1_neurons = y_train.shape[1] + (X_train.shape[1] - y_train.shape[1])*(2/3)\n",
    "    hidden2_neurons = y_train.shape[1] + (X_train.shape[1] - y_train.shape[1])*(1/3)\n",
    "    output_neurons = y_train.shape[1]\n",
    "    \n",
    "    # model construction: 2 hidden layers\n",
    "    model = Sequential([\n",
    "        Dense(hidden1_neurons, input_shape=(input_neurons,), activation='relu'),\n",
    "        Dense(hidden2_neurons, activation='relu'),\n",
    "        Dense(output_neurons)\n",
    "    ])\n",
    "    \n",
    "    # Compiling the model\n",
    "    adam = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=adam, loss='mean_squared_error', metrics=['accuracy'])\n",
    "    \n",
    "    # ToDo: define the custom evaluation metric (via keras.backend)\n",
    "    \n",
    "    # Training the model\n",
    "    history = model.fit(X_train, y_train, epochs=num_epochs, batch_size=32, validation_data=(X_val, y_val))\n",
    "    \n",
    "    # extract validation accuracy\n",
    "    validation_accuracy = history.history['val_accuracy']\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    return model, validation_accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T14:57:54.597631100Z",
     "start_time": "2023-12-02T14:57:54.588815500Z"
    }
   },
   "id": "101a27a9f9db4c86"
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "# train-val-test split, fitting linear regression model, visualize voxel predictions\n",
    "def perform_encoding(pca_dir, fmri_dir,results_dir, sub, layer, ROI = 'WB', mode = 'val', visualize_results = True):\n",
    "    \n",
    "    # Load activations (PCA outputs)\n",
    "    # ToDo: adjust pca_dir to load in all scans per subject & ROI\n",
    "    # pca_dir = os.path.join(\"/content/activations\" )\n",
    "    train_activations,test_activations = get_activations(pca_dir, layer)\n",
    "    \n",
    "    # Load fMRI data (labels)\n",
    "    # ToDO: adjust directory as soon as fMRI preprocessing is done\n",
    "    if ROI == \"WB\":\n",
    "      track = \"full_track\"\n",
    "    else:\n",
    "      track = \"mini_track\"\n",
    "    fmri_dir = os.path.join(fmri_dir, track)\n",
    "    sub_fmri_dir = os.path.join(fmri_dir, sub)\n",
    "    if track == \"full_track\":\n",
    "      fmri_train_all,voxel_mask = get_fmri(sub_fmri_dir,ROI)\n",
    "    else:\n",
    "      fmri_train_all = get_fmri(sub_fmri_dir,ROI)\n",
    "    \n",
    "    print('fmri_train_al', fmri_train_all.shape)\n",
    "    print('train_activations', train_activations.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # # calculate global mean & std_dev\n",
    "    # mean = np.mean(train_activations, axis=tuple(range(train_activations.ndim)))\n",
    "    # std_dev = np.std(train_activations, axis=tuple(range(train_activations.ndim)))\n",
    "    # \n",
    "    # # Standardize both test & train data\n",
    "    # train_activations = (train_activations - mean) / std_dev\n",
    "    # test_activations = (test_activations - mean) / std_dev\n",
    "    \n",
    "    \n",
    "    # Creating data splits\n",
    "    if mode == 'val':\n",
    "      # split labels\n",
    "      val_activations = train_activations[800:900,:]\n",
    "      train_activations = train_activations[:800,:]\n",
    "      \n",
    "      fmri_train = fmri_train_all[:800,:]\n",
    "      fmri_val = fmri_train_all[800:900,:]\n",
    "      pred_fmri = np.zeros_like(fmri_val)\n",
    "      pred_fmri_save_path = os.path.join(results_dir, ROI + '_val.npy')\n",
    "      \n",
    "      trained_model, val_acc = train_model(train_activations, val_activations, fmri_train, fmri_val)\n",
    "    \n",
    "    # ToDo @Marcel: implement predictions on test set\n",
    "    # else:\n",
    "    #     fmri_train = fmri_train_all\n",
    "    #     num_test_videos = 102\n",
    "    #     pred_fmri = np.zeros((num_test_videos,num_voxels))\n",
    "    #     pred_fmri_save_path = os.path.join(results_dir, ROI + '_test.npy')\n",
    "    ######################################\n",
    "\n",
    "    # iter = 0\n",
    "    # \n",
    "    # while iter < num_voxels-batch_size:\n",
    "    #     pred_fmri[:,iter:iter+batch_size] = predict_fmri_fast(train_activations,test_activations,fmri_train[:,iter:iter+batch_size], use_gpu = use_gpu)\n",
    "    #     iter = iter+batch_size\n",
    "    # pred_fmri[:,iter:] = predict_fmri_fast(train_activations,test_activations,fmri_train[:,iter:iter+batch_size], use_gpu = use_gpu)\n",
    "    # if mode == 'val':\n",
    "    #   score = vectorized_correlation(fmri_val,pred_fmri)\n",
    "    #   ################################################\n",
    "    # \n",
    "    #   nii_save_path =  os.path.join(results_dir, ROI + '_val.nii')\n",
    "    #   ######## Result visualization ################\n",
    "    #   if track == \"full_track\" and visualize_results:\n",
    "    #       visual_mask_3D = np.zeros((78,93,71))\n",
    "    #       visual_mask_3D[voxel_mask==1]= score\n",
    "    #       brain_mask = './example.nii'\n",
    "    #       saveasnii(brain_mask,nii_save_path,visual_mask_3D)\n",
    "    #       plotting.plot_glass_brain(nii_save_path,plot_abs=False,\n",
    "    #                         title='Correlation for ' + sub+ ' and ' + layer,\n",
    "    #                         display_mode='lyr',colorbar=True,vmin=-1,vmax=1)\n",
    "    \n",
    "    ################################################\n",
    "    # return score.mean()\n",
    "    \n",
    "    # np.save(pred_fmri_save_path, pred_fmri)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T14:44:32.405943Z",
     "start_time": "2023-12-02T14:44:32.405943Z"
    }
   },
   "id": "66325d4cba2fcf93"
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "def get_activations(activations_dir, layer):\n",
    "    \"\"\"This function loads neural network features/activations (preprocessed using PCA) into a\n",
    "    numpy array according to a given layer.\n",
    "    Parameters\n",
    "    ----------\n",
    "    activations_dir : str\n",
    "        Path to PCA processed Neural Network features\n",
    "    layer_name : str\n",
    "        which layer of the neural network to load,\n",
    "    Returns\n",
    "    -------\n",
    "    train_activations : np.array\n",
    "        matrix of dimensions #train_vids x #pca_components\n",
    "        containing activations of train videos\n",
    "    test_activations : np.array\n",
    "        matrix of dimensions #test_vids x #pca_components\n",
    "        containing activations of test videos\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # numpy arrays of the PCA results\n",
    "    # @ToDo: adjust after all PCAs are loaded here. Change paths & split in train & test. Currently, no test data is loaded\n",
    "    \n",
    "    train_activations = []\n",
    "    test_activations = [1]\n",
    "    stage_path = os.path.join(activations_dir, layer)\n",
    "    print(stage_path)\n",
    "        # Loop through each file in the folder\n",
    "    for filename in os.listdir(stage_path):\n",
    "        file_path = os.path.join(stage_path, filename)\n",
    "        with open(file_path, 'rb') as file:\n",
    "            loaded_data = pickle.load(file)\n",
    "            # Convert loaded data to NumPy array if needed\n",
    "            if isinstance(loaded_data, np.ndarray):\n",
    "                # Add a new axis before appending to the list\n",
    "                loaded_data = loaded_data[np.newaxis, ...]\n",
    "                train_activations.append(loaded_data)\n",
    "            else:\n",
    "                # Convert to array if data is not already in array format\n",
    "                loaded_data = np.array(loaded_data)\n",
    "                # Add a new axis before appending to the list\n",
    "                loaded_data = loaded_data[np.newaxis, ...]\n",
    "                train_activations.append(loaded_data)\n",
    "    \n",
    "    # Concatenate the data along the new axis (axis=0 for a new dimension)\n",
    "    train_activations = np.concatenate(train_activations, axis=0)\n",
    "    print(train_activations.shape)\n",
    "    \n",
    "    # @Todo: Remove this step after all PCA has been loaded\n",
    "    train_activations = np.concatenate([train_activations] * 200, axis=0)\n",
    "    print(train_activations.shape)\n",
    "\n",
    "    return train_activations, test_activations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T14:44:37.329961100Z",
     "start_time": "2023-12-02T14:44:37.320484100Z"
    }
   },
   "id": "4b8e62d7024d9387"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3480626c7d7508c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ROI:  WB sub:  sub01\n",
      "C:\\Users\\julia\\OneDrive - CBS - Copenhagen Business School\\Documents\\Master\\Semester3\\AdvancedML\\Brainvision_Project\\PCA\\stage_4\n",
      "(5, 30, 30)\n",
      "(1000, 30, 30)\n",
      "fmri_train_al (1000, 18222)\n",
      "train_activations (1000, 30, 30)\n",
      "X_train shape:  (800, 900)\n",
      "y_train shape:  (800, 18222)\n",
      "X_val shape:  (100, 900)\n",
      "y_val shape:  (100, 18222)\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 30s 1s/step - loss: 62.1562 - accuracy: 0.0000e+00 - val_loss: 0.2250 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2192 - accuracy: 0.0000e+00 - val_loss: 0.2195 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2174 - accuracy: 0.0000e+00 - val_loss: 0.2195 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 46s 2s/step - loss: 0.2174 - accuracy: 0.0000e+00 - val_loss: 0.2195 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 45s 2s/step - loss: 0.2174 - accuracy: 0.0000e+00 - val_loss: 0.2195 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "23/25 [==========================>...] - ETA: 2s - loss: 0.2172 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "# define directories for PCA and fmri data (repo_root necessary for runs in Ucloud)\n",
    "repo_root = find_repo_root()\n",
    "pca_dir = os.path.join(repo_root, \"PCA\")\n",
    "\n",
    "fmri_dir =  os.path.join(repo_root, \"participants_data_v2021\")\n",
    "\n",
    "prediction_dir = os.path.join(repo_root, \"participants_data_v2021\")\n",
    "\n",
    "# specify layer manually: in [\"stage_1\", \"stage_2\", \"stage_3\", \"stage_4\", \"stage_5\", \"final\"]\n",
    "layer = 'stage_4'\n",
    "\n",
    "subs = [\"sub01\",\"sub02\",\"sub03\",\"sub04\",\"sub05\",\"sub06\",\"sub07\",\"sub08\",\"sub09\",\"sub10\"]\n",
    "ROIs = [\"WB\", \"V1\", \"V2\",\"V3\", \"V4\", \"LOC\", \"EBA\", \"FFA\",\"STS\", \"PPA\"]\n",
    "for sub in subs:\n",
    "  for ROI in ROIs:\n",
    "    if ROI == \"WB\":\n",
    "        track = \"full_track\"\n",
    "    else:\n",
    "        track = \"mini_track\"\n",
    "\n",
    "    # ToDo: implement saving of prediction scores (after model construction to save prediction scores for each sub & ROI)\n",
    "    # specify directory to save prediction scores\n",
    "    results_dir = os.path.join(prediction_dir, layer, ROI, sub)  \n",
    "    if not os.path.exists(results_dir):\n",
    "      os.makedirs(results_dir)\n",
    "    \n",
    "    print (\"Starting ROI: \", ROI, \"sub: \",sub)\n",
    "    perform_encoding(pca_dir, fmri_dir,\n",
    "                     results_dir, sub, layer,\n",
    "                     ROI=ROI,mode='val')  # mode: 'val' for model training/selection, 'test' for obtaining evaluation metrics\n",
    "    print (\"Completed ROI: \", ROI, \"sub: \",sub)\n",
    "    print(\"----------------------------------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-02T15:01:36.820061500Z"
    }
   },
   "id": "40072c28e4bcaf4d"
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "# def calculate_vectorized_correlation(x, y):\n",
    "#     \"\"\"\n",
    "#     calculate evaluation score (per voxel)\n",
    "#     :param: x - prediction voxel activations; y - actual voxel activations\n",
    "#     :return: evaluation score, maybe other evaluation metrics can be added here as well\n",
    "#     \"\"\"\n",
    "#     dim = 0\n",
    "# \n",
    "#     centered_x = x - x.mean(axis=dim, keepdims=True)\n",
    "#     centered_y = y - y.mean(axis=dim, keepdims=True)\n",
    "# \n",
    "#     covariance = (centered_x * centered_y).sum(axis=dim, keepdims=True)\n",
    "# \n",
    "#     covariance = covariance / (x.shape[dim])\n",
    "# \n",
    "#     x_std = x.std(axis=dim, keepdims=True) + 1e-8\n",
    "#     y_std = y.std(axis=dim, keepdims=True) + 1e-8\n",
    "# \n",
    "#     corr = covariance / (x_std * y_std)\n",
    "# \n",
    "#     return corr.ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T15:01:31.768345200Z",
     "start_time": "2023-12-02T15:01:31.761005600Z"
    }
   },
   "id": "d947dfc873f69b3c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
