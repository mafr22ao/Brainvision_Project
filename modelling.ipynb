{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:49:15.796290700Z",
     "start_time": "2023-11-29T12:49:15.795786300Z"
    }
   },
   "outputs": [],
   "source": [
    "from fmri_preprocessing import vectorized_correlation\n",
    "from utils import find_repo_root\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train predictor with PCs as input"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1318a1adca0fa1f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d50f8e4d0d8719fa"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# fast linear regression function with Pytorch (taken from CCN2021_Algonauts.ipynb)\n",
    "class OLS_pytorch(object):\n",
    "    def __init__(self,use_gpu=False):\n",
    "        self.coefficients = []\n",
    "        self.use_gpu = use_gpu\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        if len(X.shape) == 1:\n",
    "            X = self._reshape_x(X)\n",
    "        if len(y.shape) == 1:\n",
    "            y = self._reshape_x(y)\n",
    "\n",
    "        X =  self._concatenate_ones(X)\n",
    "\n",
    "        X = torch.from_numpy(X).float()\n",
    "        y = torch.from_numpy(y).float()\n",
    "        if self.use_gpu:\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "        XtX = torch.matmul(X.t(),X)\n",
    "        Xty = torch.matmul(X.t(),y.unsqueeze(2))\n",
    "        XtX = XtX.unsqueeze(0)\n",
    "        XtX = torch.repeat_interleave(XtX, y.shape[0], dim=0)\n",
    "        betas_cholesky, _ = torch.solve(Xty, XtX)\n",
    "\n",
    "        self.coefficients = betas_cholesky\n",
    "\n",
    "    def predict(self, entry):\n",
    "        if len(entry.shape) == 1:\n",
    "            entry = self._reshape_x(entry)\n",
    "        entry =  self._concatenate_ones(entry)\n",
    "        entry = torch.from_numpy(entry).float()\n",
    "        if self.use_gpu:\n",
    "            entry = entry.cuda()\n",
    "        prediction = torch.matmul(entry,self.coefficients)\n",
    "        prediction = prediction.cpu().numpy()\n",
    "        prediction = np.squeeze(prediction).T\n",
    "        return prediction\n",
    "\n",
    "    def _reshape_x(self,X):\n",
    "        return X.reshape(-1,1)\n",
    "\n",
    "    def _concatenate_ones(self,X):\n",
    "        ones = np.ones(shape=X.shape[0]).reshape(-1,1)\n",
    "        return np.concatenate((ones,X),1)\n",
    "\n",
    "def predict_fmri_fast(train_activations, test_activations, train_fmri,use_gpu=False):\n",
    "    \"\"\"This function fits a linear regressor using train_activations and train_fmri,\n",
    "    then returns the predicted fmri_pred_test using the fitted weights and\n",
    "    test_activations.\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_activations : np.array\n",
    "        matrix of dimensions #train_vids x #pca_components\n",
    "        containing activations of train videos.\n",
    "    test_activations : np.array\n",
    "        matrix of dimensions #test_vids x #pca_components\n",
    "        containing activations of test videos\n",
    "    train_fmri : np.array\n",
    "        matrix of dimensions #train_vids x  #voxels\n",
    "        containing fMRI responses to train videos\n",
    "    use_gpu : bool\n",
    "        whether to use gpu or not.\n",
    "    Returns\n",
    "    -------\n",
    "    fmri_pred_test: np.array\n",
    "        matrix of dimensions #test_vids x  #voxels\n",
    "        containing predicted fMRI responses to test videos .\n",
    "    \"\"\"\n",
    "\n",
    "    reg = OLS_pytorch(use_gpu)\n",
    "    reg.fit(train_activations,train_fmri.T)\n",
    "    fmri_pred_test = reg.predict(test_activations)\n",
    "    return fmri_pred_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:27:30.672140Z",
     "start_time": "2023-11-29T12:27:30.669612300Z"
    }
   },
   "id": "491bdd0a0cbb2ade"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Load activations (PCA outputs)\u001B[39;00m\n\u001B[0;32m      2\u001B[0m   \u001B[38;5;66;03m# ToDo: build get_activations\u001B[39;00m\n\u001B[0;32m      3\u001B[0m   \u001B[38;5;66;03m# @Julian: change directory names as soon as PCA is done\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m repo_root \u001B[38;5;241m=\u001B[39m find_repo_root()\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(repo_root)\n\u001B[0;32m      7\u001B[0m pca_dir \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(repo_root, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPCA\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Brainvision_Project\\utils.py:8\u001B[0m, in \u001B[0;36mfind_repo_root\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfind_repo_root\u001B[39m(path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m      2\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m'''\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m    Find root path of repo.\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03m    :param path: path of current directory where executing file is stored in.\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;124;03m    :return: path: root path of repo.\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;124;03m    '''\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m     path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mabspath(path)\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misdir(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.git\u001B[39m\u001B[38;5;124m'\u001B[39m)):\n\u001B[0;32m     10\u001B[0m         parent \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mdirname(path)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Load activations (PCA outputs)\n",
    "  # ToDo: build get_activations\n",
    "  # @Julian: change directory names as soon as PCA is done\n",
    "\n",
    "repo_root = find_repo_root()\n",
    "print(repo_root)\n",
    "pca_dir = os.path.join(repo_root, \"PCA\")\n",
    "print(pca_dir)\n",
    "\n",
    "\n",
    "# train_activations,test_activations = get_activations(pca_dir, layer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:49:23.704615800Z",
     "start_time": "2023-11-29T12:49:23.673720600Z"
    }
   },
   "id": "be234434ef30fd56"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\marce\\\\PycharmProjects\\\\Brainvision_Project'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T12:45:27.084170700Z",
     "start_time": "2023-11-29T12:45:27.067767600Z"
    }
   },
   "id": "460987dbcf80ef3e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# train-val-test split, fitting linear regression model, visualize voxel predictions\n",
    "def perform_encoding(activation_dir, fmri_dir,results_dir, sub, layer, ROI = 'WB', mode = 'val', visualize_results = True, batch_size=1000):\n",
    "  if torch.cuda.is_available():\n",
    "      use_gpu = True\n",
    "  else:\n",
    "      use_gpu = False\n",
    "\n",
    "  # Load activations (PCA outputs)\n",
    "  # ToDo: build get_activations\n",
    "  # @Julian: change directory names as soon as PCA is done\n",
    "  pca_dir = os.path.join(\"/content/activations\" )\n",
    "  train_activations,test_activations = get_activations(pca_dir, layer)\n",
    "\n",
    "  # Load fMRI data (labels)\n",
    "  # @Julian: adjust directory as soon as fMRI preprocessing is done\n",
    "  if ROI == \"WB\":\n",
    "      track = \"full_track\"\n",
    "  else:\n",
    "      track = \"mini_track\"\n",
    "  fmri_dir = os.path.join(fmri_dir, track)\n",
    "  sub_fmri_dir = os.path.join(fmri_dir, sub)\n",
    "  if track == \"full_track\":\n",
    "      fmri_train_all,voxel_mask = get_fmri(sub_fmri_dir,ROI)\n",
    "  else:\n",
    "      fmri_train_all = get_fmri(sub_fmri_dir,ROI)\n",
    "  num_voxels = fmri_train_all.shape[1]\n",
    "  ######################################\n",
    "\n",
    "\n",
    "  #### Creating data splits ###############\n",
    "  if mode == 'val':\n",
    "      # split labels\n",
    "      # careful! validation activation are called \"test activations\"\n",
    "      test_activations = train_activations[800:900,:]\n",
    "      train_activations = train_activations[:800,:]\n",
    "      \n",
    "      \n",
    "      fmri_train = fmri_train_all[:800,:]\n",
    "      fmri_val = fmri_train_all[800:900,:]\n",
    "      pred_fmri = np.zeros_like(fmri_val)\n",
    "      pred_fmri_save_path = os.path.join(results_dir, ROI + '_val.npy')\n",
    "  \n",
    "  # ToDo @Marcel: implement predictions on test set\n",
    "  # else:\n",
    "  #     fmri_train = fmri_train_all\n",
    "  #     num_test_videos = 102\n",
    "  #     pred_fmri = np.zeros((num_test_videos,num_voxels))\n",
    "  #     pred_fmri_save_path = os.path.join(results_dir, ROI + '_test.npy')\n",
    "  ######################################\n",
    "\n",
    "  ######## Performing regression ################\n",
    "  iter = 0\n",
    "\n",
    "  while iter < num_voxels-batch_size:\n",
    "      pred_fmri[:,iter:iter+batch_size] = predict_fmri_fast(train_activations,test_activations,fmri_train[:,iter:iter+batch_size], use_gpu = use_gpu)\n",
    "      iter = iter+batch_size\n",
    "  pred_fmri[:,iter:] = predict_fmri_fast(train_activations,test_activations,fmri_train[:,iter:iter+batch_size], use_gpu = use_gpu)\n",
    "  if mode == 'val':\n",
    "    score = vectorized_correlation(fmri_val,pred_fmri)\n",
    "    ################################################\n",
    "\n",
    "    nii_save_path =  os.path.join(results_dir, ROI + '_val.nii')\n",
    "    ######## Result visualization ################\n",
    "    if track == \"full_track\" and visualize_results:\n",
    "        visual_mask_3D = np.zeros((78,93,71))\n",
    "        visual_mask_3D[voxel_mask==1]= score\n",
    "        brain_mask = './example.nii'\n",
    "        saveasnii(brain_mask,nii_save_path,visual_mask_3D)\n",
    "        plotting.plot_glass_brain(nii_save_path,plot_abs=False,\n",
    "                          title='Correlation for ' + sub+ ' and ' + layer,\n",
    "                          display_mode='lyr',colorbar=True,vmin=-1,vmax=1)\n",
    "\n",
    "    ################################################\n",
    "    return score.mean()\n",
    "\n",
    "  np.save(pred_fmri_save_path, pred_fmri)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T17:09:42.914620200Z",
     "start_time": "2023-11-26T17:09:42.905050400Z"
    }
   },
   "id": "66325d4cba2fcf93"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of fmri data for sub01: (1000, 3, 18222)\n",
      "Shape of fmri data for sub02: (1000, 3, 21573)\n",
      "Shape of fmri data for sub03: (1000, 3, 15225)\n",
      "Shape of fmri data for sub04: (1000, 3, 19445)\n",
      "Shape of fmri data for sub05: (1000, 3, 13340)\n",
      "Shape of fmri data for sub06: (1000, 3, 19818)\n",
      "Shape of fmri data for sub07: (1000, 3, 10836)\n",
      "Shape of fmri data for sub08: (1000, 3, 12347)\n",
      "Shape of fmri data for sub09: (1000, 3, 17570)\n",
      "Shape of fmri data for sub10: (1000, 3, 12950)\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:52:01.707687500Z",
     "start_time": "2023-11-28T17:51:58.377961500Z"
    }
   },
   "id": "857f114e929bb5ac"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\julia\\\\OneDrive - CBS - Copenhagen Business School\\\\Documents\\\\Master\\\\Semester3\\\\AdvancedML\\\\Brainvision_Project'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:43:19.587394Z",
     "start_time": "2023-11-28T17:43:19.574610400Z"
    }
   },
   "id": "f9bad39cdbf0647d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build get_activations() function\n",
    "\n",
    "def get_activations(activations_dir, layer_name):\n",
    "    \"\"\"This function loads neural network features/activations (preprocessed using PCA) into a\n",
    "    numpy array according to a given layer.\n",
    "    Parameters\n",
    "    ----------\n",
    "    activations_dir : str\n",
    "        Path to PCA processed Neural Network features\n",
    "    layer_name : str\n",
    "        which layer of the neural network to load,\n",
    "    Returns\n",
    "    -------\n",
    "    train_activations : np.array\n",
    "        matrix of dimensions #train_vids x #pca_components\n",
    "        containing activations of train videos\n",
    "    test_activations : np.array\n",
    "        matrix of dimensions #test_vids x #pca_components\n",
    "        containing activations of test videos\n",
    "    \"\"\"\n",
    "\n",
    "    train_file = os.path.join(activations_dir,\"train_\" + layer_name + \".npy\")\n",
    "    test_file = os.path.join(activations_dir,\"test_\" + layer_name + \".npy\")\n",
    "    train_activations = np.load(train_file)\n",
    "    test_activations = np.load(test_file)\n",
    "    scaler = StandardScaler()\n",
    "    train_activations = scaler.fit_transform(train_activations)\n",
    "    test_activations = scaler.fit_transform(test_activations)\n",
    "\n",
    "    return train_activations, test_activations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b8e62d7024d9387"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# # get prediction results\n",
    "# \n",
    "# # list of all subjects\n",
    "# subs = [\"sub01\",\"sub02\",\"sub03\",\"sub04\",\"sub05\",\"sub06\",\"sub07\",\"sub08\",\"sub09\",\"sub10\"]\n",
    "# \n",
    "# #root fmri directory\n",
    "# fmri_dir = './participants_data_v2021'\n",
    "# \n",
    "# # path where to save predictions\n",
    "# prediction_dir = './prediction'\n",
    "# \n",
    "# # list of ROIs\n",
    "# ROIs = [\"V1\", \"V2\",\"V3\", \"V4\", \"LOC\", \"EBA\", \"FFA\",\"STS\", \"PPA\"]\n",
    "# \n",
    "# # Initializing dictionary to store results\n",
    "# results_to_plot = {}\n",
    "# \n",
    "# # Which layer of model for prediction\n",
    "# layer = 'layer4'\n",
    "# \n",
    "# # Which track to predict\n",
    "# track = 'mini_track' \n",
    "# \n",
    "# model_name = 'resnet50'\n",
    "# \n",
    "# results_to_plot[model_name] = {}\n",
    "# # path to activations directory\n",
    "# activations_dir = \"./activations_\" + model_name # adapt to out folder structure\n",
    "# \n",
    "# # for loop running over all ROIs\n",
    "# for ROI in ROIs:\n",
    "#     results_to_plot[model_name][ROI] = 0\n",
    "#     # loop over subjects\n",
    "#     for sub in subs:\n",
    "#         # creating results directory to save results\n",
    "#         results_dir = os.path.join(prediction_dir,model_name, layer,\\\n",
    "#                             track, sub)\n",
    "#         if not os.path.exists(results_dir):\n",
    "#             os.makedirs(results_dir)\n",
    "# \n",
    "#         # encoding\n",
    "#         results_to_plot[model_name][ROI] += perform_encoding(activations_dir, fmri_dir,\\\n",
    "#                                   results_dir, sub, layer, ROI=ROI)\n",
    "#     # averaging the correlation across subjects\n",
    "#     results_to_plot[model_name][ROI]/=len(subs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:17:49.921774Z",
     "start_time": "2023-11-28T17:17:49.905507800Z"
    }
   },
   "id": "ace5a7cc9806138e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot results\n",
    "pd.DataFrame(results_to_plot).plot(kind='bar')\n",
    "\n",
    "plt.title(\"Correlation with validation set: \" + layer)\n",
    "plt.ylabel(\"Correlation\")\n",
    "plt.xlabel(\"ROIs\")\n",
    "plt.ylim([0,0.5])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e933b4175b358d21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate predictions over all subs and ROIs and save them in folders (modes can be 'val' or 'test')\n",
    "subs = [\"sub01\",\"sub02\",\"sub03\",\"sub04\",\"sub05\",\"sub06\",\"sub07\",\"sub08\",\"sub09\",\"sub10\"]\n",
    "ROIs = [\"WB\", \"V1\", \"V2\",\"V3\", \"V4\", \"LOC\", \"EBA\", \"FFA\",\"STS\", \"PPA\"]\n",
    "layer = 'layer4'\n",
    "model = 'r3d_18'\n",
    "for sub in subs:\n",
    "  # leaving ROI choice in the code for now - can be removed later\n",
    "  for ROI in ROIs:\n",
    "    if ROI == \"WB\":\n",
    "        track = \"full_track\"\n",
    "    else:\n",
    "        track = \"mini_track\"\n",
    "    results_dir = os.path.join(prediction_dir,model, layer, track, sub)  # directory to save prediction scores\n",
    "    if not os.path.exists(results_dir):\n",
    "      os.makedirs(results_dir)\n",
    "    print (\"Starting ROI: \", ROI, \"sub: \",sub)\n",
    "    perform_encoding(activations_dir, fmri_dir,\\\n",
    "                     results_dir, sub, layer,\\\n",
    "                     ROI=ROI,mode='val')  # mode: 'val' for model training/selection, 'test' for obtaining evaluation metrics\n",
    "    print (\"Completed ROI: \", ROI, \"sub: \",sub)\n",
    "    print(\"----------------------------------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40072c28e4bcaf4d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_vectorized_correlation(x, y):\n",
    "    \"\"\"\n",
    "    calculate evaluation score (per voxel)\n",
    "    :param: x - prediction voxel activations; y - actual voxel activations\n",
    "    :return: evaluation score, maybe other evaluation metrics can be added here as well\n",
    "    \"\"\"\n",
    "    dim = 0\n",
    "\n",
    "    centered_x = x - x.mean(axis=dim, keepdims=True)\n",
    "    centered_y = y - y.mean(axis=dim, keepdims=True)\n",
    "\n",
    "    covariance = (centered_x * centered_y).sum(axis=dim, keepdims=True)\n",
    "\n",
    "    covariance = covariance / (x.shape[dim])\n",
    "\n",
    "    x_std = x.std(axis=dim, keepdims=True) + 1e-8\n",
    "    y_std = y.std(axis=dim, keepdims=True) + 1e-8\n",
    "\n",
    "    corr = covariance / (x_std * y_std)\n",
    "\n",
    "    return corr.ravel()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d947dfc873f69b3c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
