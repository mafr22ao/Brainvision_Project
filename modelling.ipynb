{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:37:52.312884200Z",
     "start_time": "2023-12-01T14:37:52.297493200Z"
    }
   },
   "outputs": [],
   "source": [
    "from fmri_preprocessing import vectorized_correlation\n",
    "from utils import find_repo_root\n",
    "from utils import load_dict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Function Definitions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cef70d0abaf40bf4"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# fast linear regression function with Pytorch (taken from CCN2021_Algonauts.ipynb)\n",
    "# class OLS_pytorch(object):\n",
    "#     def __init__(self,use_gpu=False):\n",
    "#         self.coefficients = []\n",
    "#         self.use_gpu = use_gpu\n",
    "#         self.X = None\n",
    "#         self.y = None\n",
    "# \n",
    "#     def fit(self,X,y):\n",
    "#         if len(X.shape) == 1:\n",
    "#             X = self._reshape_x(X)\n",
    "#         if len(y.shape) == 1:\n",
    "#             y = self._reshape_x(y)\n",
    "# \n",
    "#         X =  self._concatenate_ones(X)\n",
    "# \n",
    "#         X = torch.from_numpy(X).float()\n",
    "#         y = torch.from_numpy(y).float()\n",
    "#         if self.use_gpu:\n",
    "#             X = X.cuda()\n",
    "#             y = y.cuda()\n",
    "#         XtX = torch.matmul(X.t(),X)\n",
    "#         Xty = torch.matmul(X.t(),y.unsqueeze(2))\n",
    "#         XtX = XtX.unsqueeze(0)\n",
    "#         XtX = torch.repeat_interleave(XtX, y.shape[0], dim=0)\n",
    "#         betas_cholesky, _ = torch.solve(Xty, XtX)\n",
    "# \n",
    "#         self.coefficients = betas_cholesky\n",
    "# \n",
    "#     def predict(self, entry):\n",
    "#         if len(entry.shape) == 1:\n",
    "#             entry = self._reshape_x(entry)\n",
    "#         entry =  self._concatenate_ones(entry)\n",
    "#         entry = torch.from_numpy(entry).float()\n",
    "#         if self.use_gpu:\n",
    "#             entry = entry.cuda()\n",
    "#         prediction = torch.matmul(entry,self.coefficients)\n",
    "#         prediction = prediction.cpu().numpy()\n",
    "#         prediction = np.squeeze(prediction).T\n",
    "#         return prediction\n",
    "# \n",
    "#     def _reshape_x(self,X):\n",
    "#         return X.reshape(-1,1)\n",
    "# \n",
    "#     def _concatenate_ones(self,X):\n",
    "#         ones = np.ones(shape=X.shape[0]).reshape(-1,1)\n",
    "#         return np.concatenate((ones,X),1)\n",
    "\n",
    "# def predict_fmri_fast(train_activations, test_activations, train_fmri,use_gpu=False):\n",
    "#     \"\"\"This function fits a linear regressor using train_activations and train_fmri,\n",
    "#     then returns the predicted fmri_pred_test using the fitted weights and\n",
    "#     test_activations.\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     train_activations : np.array\n",
    "#         matrix of dimensions #train_vids x #pca_components\n",
    "#         containing activations of train videos.\n",
    "#     test_activations : np.array\n",
    "#         matrix of dimensions #test_vids x #pca_components\n",
    "#         containing activations of test videos\n",
    "#     train_fmri : np.array\n",
    "#         matrix of dimensions #train_vids x  #voxels\n",
    "#         containing fMRI responses to train videos\n",
    "#     use_gpu : bool\n",
    "#         whether to use gpu or not.\n",
    "#     Returns\n",
    "#     -------\n",
    "#     fmri_pred_test: np.array\n",
    "#         matrix of dimensions #test_vids x  #voxels\n",
    "#         containing predicted fMRI responses to test videos .\n",
    "#     \"\"\"\n",
    "# \n",
    "#     reg = OLS_pytorch(use_gpu)\n",
    "#     reg.fit(train_activations,train_fmri.T)\n",
    "#     fmri_pred_test = reg.predict(test_activations)\n",
    "#     return fmri_pred_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T17:09:09.875257200Z",
     "start_time": "2023-11-26T17:09:09.862242300Z"
    }
   },
   "id": "491bdd0a0cbb2ade"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_fmri(fmri_dir, ROI):\n",
    "    \"\"\"This function loads fMRI data into a numpy array for to a given ROI.\n",
    "    Parameters\n",
    "    ----------\n",
    "    fmri_dir : str\n",
    "        path to fMRI data. Relates to a specific subject.\n",
    "    ROI : str\n",
    "        name of ROI.\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        matrix of dimensions #train_vids x #repetitions x #voxels\n",
    "        containing fMRI responses to train videos of a given ROI\n",
    "    \"\"\"\n",
    "\n",
    "    # Loading ROI data\n",
    "    # @Julian: adjust path as soon as preprocessing is done\n",
    "    ROI_file = os.path.join(fmri_dir, ROI + \".pkl\")\n",
    "    ROI_data = load_dict(ROI_file)\n",
    "\n",
    "    # averaging ROI data across repetitions\n",
    "    ROI_data_train = np.mean(ROI_data[\"train\"], axis = 1)\n",
    "    if ROI == \"WB\":\n",
    "        voxel_mask = ROI_data['voxel_mask']\n",
    "        return ROI_data_train, voxel_mask\n",
    "\n",
    "    return ROI_data_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:16:01.906307200Z",
     "start_time": "2023-12-01T14:16:01.876498100Z"
    }
   },
   "id": "5dd959a6472e9324"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Dense Layer\n",
    "def train_model(X_train, X_val, y_train, y_val, num_epochs = 1000):\n",
    "    \"\"\"\n",
    "    conducts the training for a particular layer, subject & ROI\n",
    "    :param X_train: training data (feature map PCs from first 800 videos from a particular layer)\n",
    "    :param X_val: validation data (feature map PCs from videos 801-900 from a particular layer)\n",
    "    :param y_train: training labels (scans for first 800 videos for the particular subject & ROI)\n",
    "    :param y_val: training labels (scans for videos 801-900 for the particular subject & ROI)\n",
    "    :param num_epochs: number of epochs for training\n",
    "    :return: model parameters & validation accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    # specify number of neurons per layer, depending on the number of inputs from a particular layer and number of output voxels\n",
    "    input_neurons = X_train.shape[1]\n",
    "    hidden1_neurons = y_train.shape[1] + (X_train.shape[1] - y_train.shape[1])*(2/3)\n",
    "    hidden2_neurons = y_train.shape[1] + (X_train.shape[1] - y_train.shape[1])*(1/3)\n",
    "    output_neurons = y_train.shape[1]\n",
    "    \n",
    "    # model construction: 2 hidden layers\n",
    "    model = Sequential([\n",
    "        Dense(hidden1_neurons, input_shape=(input_neurons,), activation='relu'),\n",
    "        Dense(hidden2_neurons, activation='relu'),\n",
    "        Dense(output_neurons)\n",
    "    ])\n",
    "    \n",
    "    # Compiling the model\n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(optimizer=adam, loss='mean_squared_error')\n",
    "    \n",
    "    # ToDo: define the custom evaluation metric (via keras.backend)\n",
    "    \n",
    "    # Training the model\n",
    "    history = model.fit(X_train, y_train, epochs=num_epochs, batch_size=32, validation_data=(X_val, y_val))\n",
    "    \n",
    "    # extract validation accuracy\n",
    "    validation_accuracy = history.history['val_accuracy']\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    return model, validation_accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:16:04.685555400Z",
     "start_time": "2023-12-01T14:16:04.674571100Z"
    }
   },
   "id": "101a27a9f9db4c86"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (853691021.py, line 53)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[5], line 53\u001B[1;36m\u001B[0m\n\u001B[1;33m    trained_model = simple_nn_training(input_size, hidden_size, output_size, x_train, y_train)\u001B[0m\n\u001B[1;37m    ^\u001B[0m\n\u001B[1;31mIndentationError\u001B[0m\u001B[1;31m:\u001B[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# train-val-test split, fitting linear regression model, visualize voxel predictions\n",
    "def perform_encoding(pca_dir, fmri_dir,results_dir, sub, layer, ROI = 'WB', mode = 'val', visualize_results = True, batch_size=1000):\n",
    "    if torch.cuda.is_available():\n",
    "      use_gpu = True\n",
    "    else:\n",
    "      use_gpu = False\n",
    "    \n",
    "    # Load activations (PCA outputs)\n",
    "    # ToDo: build get_activations\n",
    "    # @Julian: change directory names as soon as PCA is done\n",
    "    pca_dir = os.path.join(\"/content/activations\" )\n",
    "    train_activations,test_activations = get_activations(pca_dir, layer)\n",
    "    \n",
    "    # Load fMRI data (labels)\n",
    "    # ToDO: adjust directory as soon as fMRI preprocessing is done\n",
    "    if ROI == \"WB\":\n",
    "      track = \"full_track\"\n",
    "    else:\n",
    "      track = \"mini_track\"\n",
    "    fmri_dir = os.path.join(fmri_dir, track)\n",
    "    sub_fmri_dir = os.path.join(fmri_dir, sub)\n",
    "    if track == \"full_track\":\n",
    "      fmri_train_all,voxel_mask = get_fmri(sub_fmri_dir,ROI)\n",
    "    else:\n",
    "      fmri_train_all = get_fmri(sub_fmri_dir,ROI)\n",
    "    num_voxels = fmri_train_all.shape[1]\n",
    "    \n",
    "    \n",
    "    # Creating data splits\n",
    "    if mode == 'val':\n",
    "      # split labels\n",
    "      train_activations = train_activations[800:900,:]\n",
    "      val_activations = train_activations[:800,:]\n",
    "      \n",
    "      \n",
    "      fmri_train = fmri_train_all[:800,:]\n",
    "      fmri_val = fmri_train_all[800:900,:]\n",
    "      pred_fmri = np.zeros_like(fmri_val)\n",
    "      pred_fmri_save_path = os.path.join(results_dir, ROI + '_val.npy')\n",
    "      \n",
    "      trained_model, val_acc = train_model(train_activations, val_activations, fmri_train, fmri_val)\n",
    "    \n",
    "    # ToDo @Marcel: implement predictions on test set\n",
    "    # else:\n",
    "    #     fmri_train = fmri_train_all\n",
    "    #     num_test_videos = 102\n",
    "    #     pred_fmri = np.zeros((num_test_videos,num_voxels))\n",
    "    #     pred_fmri_save_path = os.path.join(results_dir, ROI + '_test.npy')\n",
    "    ######################################\n",
    "\n",
    "    # iter = 0\n",
    "    # \n",
    "    # while iter < num_voxels-batch_size:\n",
    "    #     pred_fmri[:,iter:iter+batch_size] = predict_fmri_fast(train_activations,test_activations,fmri_train[:,iter:iter+batch_size], use_gpu = use_gpu)\n",
    "    #     iter = iter+batch_size\n",
    "    # pred_fmri[:,iter:] = predict_fmri_fast(train_activations,test_activations,fmri_train[:,iter:iter+batch_size], use_gpu = use_gpu)\n",
    "    # if mode == 'val':\n",
    "    #   score = vectorized_correlation(fmri_val,pred_fmri)\n",
    "    #   ################################################\n",
    "    # \n",
    "    #   nii_save_path =  os.path.join(results_dir, ROI + '_val.nii')\n",
    "    #   ######## Result visualization ################\n",
    "    #   if track == \"full_track\" and visualize_results:\n",
    "    #       visual_mask_3D = np.zeros((78,93,71))\n",
    "    #       visual_mask_3D[voxel_mask==1]= score\n",
    "    #       brain_mask = './example.nii'\n",
    "    #       saveasnii(brain_mask,nii_save_path,visual_mask_3D)\n",
    "    #       plotting.plot_glass_brain(nii_save_path,plot_abs=False,\n",
    "    #                         title='Correlation for ' + sub+ ' and ' + layer,\n",
    "    #                         display_mode='lyr',colorbar=True,vmin=-1,vmax=1)\n",
    "    \n",
    "    ################################################\n",
    "    # return score.mean()\n",
    "    \n",
    "    # np.save(pred_fmri_save_path, pred_fmri)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:16:09.859361400Z",
     "start_time": "2023-12-01T14:16:09.849717500Z"
    }
   },
   "id": "66325d4cba2fcf93"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of fmri data for sub01: (1000, 3, 18222)\n",
      "Shape of fmri data for sub02: (1000, 3, 21573)\n",
      "Shape of fmri data for sub03: (1000, 3, 15225)\n",
      "Shape of fmri data for sub04: (1000, 3, 19445)\n",
      "Shape of fmri data for sub05: (1000, 3, 13340)\n",
      "Shape of fmri data for sub06: (1000, 3, 19818)\n",
      "Shape of fmri data for sub07: (1000, 3, 10836)\n",
      "Shape of fmri data for sub08: (1000, 3, 12347)\n",
      "Shape of fmri data for sub09: (1000, 3, 17570)\n",
      "Shape of fmri data for sub10: (1000, 3, 12950)\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:52:01.707687500Z",
     "start_time": "2023-11-28T17:51:58.377961500Z"
    }
   },
   "id": "857f114e929bb5ac"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\julia\\\\OneDrive - CBS - Copenhagen Business School\\\\Documents\\\\Master\\\\Semester3\\\\AdvancedML\\\\Brainvision_Project'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:43:19.587394Z",
     "start_time": "2023-11-28T17:43:19.574610400Z"
    }
   },
   "id": "f9bad39cdbf0647d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_activations(activations_dir, layer_name):\n",
    "    \"\"\"This function loads neural network features/activations (preprocessed using PCA) into a\n",
    "    numpy array according to a given layer.\n",
    "    Parameters\n",
    "    ----------\n",
    "    activations_dir : str\n",
    "        Path to PCA processed Neural Network features\n",
    "    layer_name : str\n",
    "        which layer of the neural network to load,\n",
    "    Returns\n",
    "    -------\n",
    "    train_activations : np.array\n",
    "        matrix of dimensions #train_vids x #pca_components\n",
    "        containing activations of train videos\n",
    "    test_activations : np.array\n",
    "        matrix of dimensions #test_vids x #pca_components\n",
    "        containing activations of test videos\n",
    "    \"\"\"\n",
    "    # @Julian: adjust paths as soon as created\n",
    "    \n",
    "    # numpy arrays of the PCA results\n",
    "    # \"train\" contains PCA outputs of all videos, \"test\" is for the validation set\n",
    "    train_file = os.path.join(activations_dir,\"train_\" + layer_name + \".npy\")\n",
    "    test_file = os.path.join(activations_dir,\"test_\" + layer_name + \".npy\")\n",
    "    train_activations = np.load(train_file)\n",
    "    test_activations = np.load(test_file)\n",
    "    \n",
    "    # standardize PCA output\n",
    "    scaler = StandardScaler()\n",
    "    train_activations = scaler.fit_transform(train_activations)\n",
    "    test_activations = scaler.fit_transform(test_activations)\n",
    "\n",
    "    return train_activations, test_activations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b8e62d7024d9387"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# # get prediction results\n",
    "# \n",
    "# # list of all subjects\n",
    "# subs = [\"sub01\",\"sub02\",\"sub03\",\"sub04\",\"sub05\",\"sub06\",\"sub07\",\"sub08\",\"sub09\",\"sub10\"]\n",
    "# \n",
    "# #root fmri directory\n",
    "# fmri_dir = './participants_data_v2021'\n",
    "# \n",
    "# # path where to save predictions\n",
    "# prediction_dir = './prediction'\n",
    "# \n",
    "# # list of ROIs\n",
    "# ROIs = [\"V1\", \"V2\",\"V3\", \"V4\", \"LOC\", \"EBA\", \"FFA\",\"STS\", \"PPA\"]\n",
    "# \n",
    "# # Initializing dictionary to store results\n",
    "# results_to_plot = {}\n",
    "# \n",
    "# # Which layer of model for prediction\n",
    "# layer = 'layer4'\n",
    "# \n",
    "# # Which track to predict\n",
    "# track = 'mini_track' \n",
    "# \n",
    "# model_name = 'resnet50'\n",
    "# \n",
    "# results_to_plot[model_name] = {}\n",
    "# # path to activations directory\n",
    "# activations_dir = \"./activations_\" + model_name # adapt to out folder structure\n",
    "# \n",
    "# # for loop running over all ROIs\n",
    "# for ROI in ROIs:\n",
    "#     results_to_plot[model_name][ROI] = 0\n",
    "#     # loop over subjects\n",
    "#     for sub in subs:\n",
    "#         # creating results directory to save results\n",
    "#         results_dir = os.path.join(prediction_dir,model_name, layer,\\\n",
    "#                             track, sub)\n",
    "#         if not os.path.exists(results_dir):\n",
    "#             os.makedirs(results_dir)\n",
    "# \n",
    "#         # encoding\n",
    "#         results_to_plot[model_name][ROI] += perform_encoding(activations_dir, fmri_dir,\\\n",
    "#                                   results_dir, sub, layer, ROI=ROI)\n",
    "#     # averaging the correlation across subjects\n",
    "#     results_to_plot[model_name][ROI]/=len(subs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:17:49.921774Z",
     "start_time": "2023-11-28T17:17:49.905507800Z"
    }
   },
   "id": "ace5a7cc9806138e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot results\n",
    "pd.DataFrame(results_to_plot).plot(kind='bar')\n",
    "\n",
    "plt.title(\"Correlation with validation set: \" + layer)\n",
    "plt.ylabel(\"Correlation\")\n",
    "plt.xlabel(\"ROIs\")\n",
    "plt.ylim([0,0.5])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e933b4175b358d21"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3480626c7d7508c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define repo root (necessary for runs in Ucloud)\n",
    "repo_root = find_repo_root()\n",
    "pca_dir = os.path.join(repo_root, \"PCA\")\n",
    "print(pca_dir)\n",
    "\n",
    "# specify layer manually: [\"stage_1\", \"stage_2\", \"stage_3\", \"stage_4\", \"stage_5\", \"final\"]\n",
    "layer = 'layer4'\n",
    "\n",
    "subs = [\"sub01\",\"sub02\",\"sub03\",\"sub04\",\"sub05\",\"sub06\",\"sub07\",\"sub08\",\"sub09\",\"sub10\"]\n",
    "ROIs = [\"WB\", \"V1\", \"V2\",\"V3\", \"V4\", \"LOC\", \"EBA\", \"FFA\",\"STS\", \"PPA\"]\n",
    "for sub in subs:\n",
    "  # leaving ROI choice in the code for now - can be removed later\n",
    "  for ROI in ROIs:\n",
    "    if ROI == \"WB\":\n",
    "        track = \"full_track\"\n",
    "    else:\n",
    "        track = \"mini_track\"\n",
    "\n",
    "    # ToDo: implement some saving of prediction scores\n",
    "    # specify directory to save prediction scores\n",
    "    # results_dir = os.path.join(prediction_dir,model, layer, track, sub)  \n",
    "    # if not os.path.exists(results_dir):\n",
    "    #   os.makedirs(results_dir)\n",
    "    print (\"Starting ROI: \", ROI, \"sub: \",sub)\n",
    "    perform_encoding(pca_dir, fmri_dir,\\\n",
    "                     results_dir, sub, layer,\\\n",
    "                     ROI=ROI,mode='val')  # mode: 'val' for model training/selection, 'test' for obtaining evaluation metrics\n",
    "    print (\"Completed ROI: \", ROI, \"sub: \",sub)\n",
    "    print(\"----------------------------------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40072c28e4bcaf4d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def calculate_vectorized_correlation(x, y):\n",
    "#     \"\"\"\n",
    "#     calculate evaluation score (per voxel)\n",
    "#     :param: x - prediction voxel activations; y - actual voxel activations\n",
    "#     :return: evaluation score, maybe other evaluation metrics can be added here as well\n",
    "#     \"\"\"\n",
    "#     dim = 0\n",
    "# \n",
    "#     centered_x = x - x.mean(axis=dim, keepdims=True)\n",
    "#     centered_y = y - y.mean(axis=dim, keepdims=True)\n",
    "# \n",
    "#     covariance = (centered_x * centered_y).sum(axis=dim, keepdims=True)\n",
    "# \n",
    "#     covariance = covariance / (x.shape[dim])\n",
    "# \n",
    "#     x_std = x.std(axis=dim, keepdims=True) + 1e-8\n",
    "#     y_std = y.std(axis=dim, keepdims=True) + 1e-8\n",
    "# \n",
    "#     corr = covariance / (x_std * y_std)\n",
    "# \n",
    "#     return corr.ravel()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d947dfc873f69b3c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
